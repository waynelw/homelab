# ğŸ§ª Kubernetes å­¦ä¹ å®éªŒè®¾è®¡

åŸºäºä½ çš„ **Kind + Flux + Tekton** ç¯å¢ƒï¼Œè®¾è®¡ä»¥ä¸‹å¾ªåºæ¸è¿›çš„å®éªŒæ¥å­¦ä¹  Kubernetes æ ¸å¿ƒåŸç†ã€‚

## ğŸ“š å®éªŒä½“ç³»æ¦‚è§ˆ

```
å®éªŒä½“ç³»
â”œâ”€â”€ åŸºç¡€ç¯‡: Pod å’Œå®¹å™¨ç”Ÿå‘½å‘¨æœŸ
â”œâ”€â”€ æ§åˆ¶å™¨ç¯‡: Deployment/StatefulSet/DaemonSet
â”œâ”€â”€ ç½‘ç»œç¯‡: Service/Ingress/NetworkPolicy
â”œâ”€â”€ å­˜å‚¨ç¯‡: Volume/PV/PVC/StorageClass
â”œâ”€â”€ é…ç½®ç¯‡: ConfigMap/Secret
â”œâ”€â”€ å®‰å…¨ç¯‡: RBAC/ServiceAccount/SecurityContext
â”œâ”€â”€ è°ƒåº¦ç¯‡: Scheduler/Affinity/Taints/Tolerations
â”œâ”€â”€ ç›‘æ§ç¯‡: Metrics/Logging/Tracing
â””â”€â”€ GitOpsç¯‡: Flux/Tekton æ·±å…¥å®è·µ
```

---

# ğŸ“– å®éªŒä¸€ï¼šPod ç”Ÿå‘½å‘¨æœŸæ·±åº¦æ¢ç´¢

## ğŸ¯ å­¦ä¹ ç›®æ ‡
- ç†è§£ Pod çš„åˆ›å»ºã€è¿è¡Œã€é”€æ¯å…¨ç”Ÿå‘½å‘¨æœŸ
- æŒæ¡å®¹å™¨é‡å¯ç­–ç•¥å’Œå¥åº·æ£€æŸ¥æœºåˆ¶
- è§‚å¯Ÿ Init Container å’Œ Sidecar æ¨¡å¼

## ğŸ”¬ å®éªŒæ­¥éª¤

### 1.1 åˆ›å»ºåŸºç¡€ Pod å¹¶è§‚å¯Ÿç”Ÿå‘½å‘¨æœŸ

```yaml
# experiments/01-pod-lifecycle/basic-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: lifecycle-demo
  namespace: experiments
  labels:
    app: lifecycle-demo
spec:
  containers:
  - name: main
    image: nginx:alpine
    lifecycle:
      postStart:
        exec:
          command: ["/bin/sh", "-c", "echo 'PostStart: Pod started at $(date)' > /usr/share/nginx/html/lifecycle.log"]
      preStop:
        exec:
          command: ["/bin/sh", "-c", "sleep 10 && echo 'PreStop: Pod stopping at $(date)' >> /usr/share/nginx/html/lifecycle.log"]
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 3
      periodSeconds: 5
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 2
      periodSeconds: 3
```

**è§‚å¯Ÿå‘½ä»¤**:
```bash
# åˆ›å»ºå‘½åç©ºé—´
kubectl create namespace experiments

# åº”ç”¨é…ç½®
kubectl apply -f experiments/01-pod-lifecycle/basic-pod.yaml

# å®æ—¶æŸ¥çœ‹Podäº‹ä»¶
kubectl get events -n experiments --watch

# æŸ¥çœ‹Podè¯¦ç»†ä¿¡æ¯
kubectl describe pod lifecycle-demo -n experiments

# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
kubectl logs lifecycle-demo -n experiments

# åˆ é™¤Podè§‚å¯ŸpreStopé’©å­
kubectl delete pod lifecycle-demo -n experiments
```

**é¢„æœŸå­¦ä¹ **:
- Pod çš„ Pending â†’ Running â†’ Terminating çŠ¶æ€è½¬æ¢
- postStart å’Œ preStop é’©å­çš„æ‰§è¡Œæ—¶æœº
- å¥åº·æ£€æŸ¥å¦‚ä½•å½±å“ Pod çŠ¶æ€

---

### 1.2 æ¢ç´¢é‡å¯ç­–ç•¥

```yaml
# experiments/01-pod-lifecycle/restart-policy.yaml
apiVersion: v1
kind: Pod
metadata:
  name: restart-demo
  namespace: experiments
spec:
  restartPolicy: OnFailure  # ä¿®æ”¹ä¸º Always, Never å¯¹æ¯”
  containers:
  - name: crash-loop
    image: busybox
    command: ["sh", "-c", "echo 'Starting...'; sleep 10; exit 1"]
```

**å®éªŒä»»åŠ¡**:
```bash
# åº”ç”¨Pod
kubectl apply -f experiments/01-pod-lifecycle/restart-policy.yaml

# è§‚å¯Ÿé‡å¯æ¬¡æ•°
kubectl get pod restart-demo -n experiments -w

# æŸ¥çœ‹é‡å¯å†å²
kubectl describe pod restart-demo -n experiments | grep -A 10 "State:"

# ä¿®æ”¹ restartPolicy ä¸º Neverï¼Œè§‚å¯Ÿå·®å¼‚
# ä¿®æ”¹ exit 1 ä¸º exit 0ï¼Œè§‚å¯ŸæˆåŠŸé€€å‡ºçš„è¡Œä¸º
```

**å…³é”®é—®é¢˜**:
- ä¸ºä»€ä¹ˆ CrashLoopBackOff çš„é‡å¯é—´éš”ä¼šè¶Šæ¥è¶Šé•¿ï¼Ÿ
- restartPolicy å¦‚ä½•å½±å“ Pod çš„è¡Œä¸ºï¼Ÿ

---

### 1.3 Init Container å®éªŒ

```yaml
# experiments/01-pod-lifecycle/init-container.yaml
apiVersion: v1
kind: Pod
metadata:
  name: init-demo
  namespace: experiments
spec:
  initContainers:
  - name: init-1
    image: busybox
    command: ['sh', '-c', 'echo "Init 1: Checking database..." && sleep 5']
  - name: init-2
    image: busybox
    command: ['sh', '-c', 'echo "Init 2: Loading config..." && sleep 3']
  containers:
  - name: app
    image: nginx:alpine
    ports:
    - containerPort: 80
```

**è§‚å¯Ÿå‘½ä»¤**:
```bash
kubectl apply -f experiments/01-pod-lifecycle/init-container.yaml

# è§‚å¯ŸInitå®¹å™¨æŒ‰é¡ºåºæ‰§è¡Œ
kubectl get pod init-demo -n experiments -w

# æŸ¥çœ‹Initå®¹å™¨æ—¥å¿—
kubectl logs init-demo -n experiments -c init-1
kubectl logs init-demo -n experiments -c init-2
```

**å­¦ä¹ é‡ç‚¹**:
- Init Container çš„ä¸²è¡Œæ‰§è¡Œæœºåˆ¶
- Init Container å¤±è´¥å¯¹ Pod å¯åŠ¨çš„å½±å“

---

# ğŸ“– å®éªŒäºŒï¼šæ§åˆ¶å™¨æœºåˆ¶æ·±å…¥

## ğŸ¯ å­¦ä¹ ç›®æ ‡
- ç†è§£ Deployment çš„æ»šåŠ¨æ›´æ–°å’Œå›æ»šæœºåˆ¶
- æŒæ¡ StatefulSet çš„æœ‰åºéƒ¨ç½²å’ŒæŒä¹…åŒ–
- äº†è§£ DaemonSet çš„èŠ‚ç‚¹çº§éƒ¨ç½²

## ğŸ”¬ å®éªŒæ­¥éª¤

### 2.1 Deployment æ»šåŠ¨æ›´æ–°å®éªŒ

```yaml
# experiments/02-controllers/rolling-update.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rolling-demo
  namespace: experiments
spec:
  replicas: 6
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 2
  selector:
    matchLabels:
      app: rolling-demo
  template:
    metadata:
      labels:
        app: rolling-demo
    spec:
      containers:
      - name: app
        image: nginx:1.21-alpine
        ports:
        - containerPort: 80
        readinessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 2
          periodSeconds: 2
```

**å®éªŒä»»åŠ¡**:
```bash
# éƒ¨ç½²åº”ç”¨
kubectl apply -f experiments/02-controllers/rolling-update.yaml

# è§‚å¯Ÿåˆå§‹çŠ¶æ€
kubectl get deployment rolling-demo -n experiments
kubectl get rs -n experiments -l app=rolling-demo

# è§¦å‘æ»šåŠ¨æ›´æ–°
kubectl set image deployment/rolling-demo app=nginx:1.22-alpine -n experiments

# å®æ—¶è§‚å¯Ÿæ›´æ–°è¿‡ç¨‹
kubectl rollout status deployment/rolling-demo -n experiments
kubectl get pods -n experiments -l app=rolling-demo -w

# æŸ¥çœ‹ReplicaSetå˜åŒ–
kubectl get rs -n experiments -l app=rolling-demo

# æŸ¥çœ‹æ»šåŠ¨å†å²
kubectl rollout history deployment/rolling-demo -n experiments

# å›æ»šåˆ°ä¸Šä¸€ç‰ˆæœ¬
kubectl rollout undo deployment/rolling-demo -n experiments

# å›æ»šåˆ°ç‰¹å®šç‰ˆæœ¬
kubectl rollout undo deployment/rolling-demo --to-revision=1 -n experiments
```

**æ·±å…¥æ¢ç´¢**:
```bash
# ä¿®æ”¹ maxUnavailable å’Œ maxSurge è§‚å¯Ÿå·®å¼‚
kubectl patch deployment rolling-demo -n experiments -p '{"spec":{"strategy":{"rollingUpdate":{"maxUnavailable":0,"maxSurge":1}}}}'

# æš‚åœå’Œæ¢å¤æ»šåŠ¨æ›´æ–°
kubectl rollout pause deployment/rolling-demo -n experiments
kubectl rollout resume deployment/rolling-demo -n experiments
```

**å…³é”®é—®é¢˜**:
- maxUnavailable å’Œ maxSurge å¦‚ä½•å½±å“æ›´æ–°é€Ÿåº¦ï¼Ÿ
- ReplicaSet åœ¨æ»šåŠ¨æ›´æ–°ä¸­çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ
- ä¸ºä»€ä¹ˆéœ€è¦ readinessProbeï¼Ÿ

---

### 2.2 StatefulSet æœ‰åºéƒ¨ç½²å®éªŒ

```yaml
# experiments/02-controllers/statefulset.yaml
apiVersion: v1
kind: Service
metadata:
  name: stateful-svc
  namespace: experiments
spec:
  clusterIP: None  # Headless Service
  selector:
    app: stateful-demo
  ports:
  - port: 80
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: stateful-demo
  namespace: experiments
spec:
  serviceName: stateful-svc
  replicas: 3
  selector:
    matchLabels:
      app: stateful-demo
  template:
    metadata:
      labels:
        app: stateful-demo
    spec:
      containers:
      - name: app
        image: nginx:alpine
        volumeMounts:
        - name: data
          mountPath: /data
        command: ["/bin/sh"]
        args:
        - -c
        - |
          echo "Pod: $HOSTNAME" > /data/hostname.txt
          echo "Started at: $(date)" >> /data/hostname.txt
          nginx -g 'daemon off;'
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 1Gi
```

**è§‚å¯Ÿå‘½ä»¤**:
```bash
# éƒ¨ç½²StatefulSet
kubectl apply -f experiments/02-controllers/statefulset.yaml

# è§‚å¯Ÿæœ‰åºåˆ›å»º
kubectl get pods -n experiments -l app=stateful-demo -w

# æŸ¥çœ‹Podåç§°å’ŒæŒä¹…åŒ–å­˜å‚¨
kubectl get pods -n experiments -l app=stateful-demo
kubectl get pvc -n experiments

# è¿›å…¥PodéªŒè¯æŒä¹…åŒ–
kubectl exec stateful-demo-0 -n experiments -- cat /data/hostname.txt

# åˆ é™¤Podè§‚å¯Ÿé‡å»º
kubectl delete pod stateful-demo-1 -n experiments
kubectl get pods -n experiments -l app=stateful-demo -w

# æµ‹è¯•Headless Service DNS
kubectl run -it --rm debug --image=busybox --restart=Never -n experiments -- nslookup stateful-svc.experiments.svc.cluster.local
kubectl run -it --rm debug --image=busybox --restart=Never -n experiments -- nslookup stateful-demo-0.stateful-svc.experiments.svc.cluster.local
```

**å…³é”®é—®é¢˜**:
- StatefulSet çš„ Pod åç§°æœ‰ä»€ä¹ˆè§„å¾‹ï¼Ÿ
- åˆ é™¤çš„ Pod é‡å»ºå PVC æ˜¯å¦è¿˜åœ¨ï¼Ÿ
- Headless Service çš„ DNS è§£ææœ‰ä½•ç‰¹ç‚¹ï¼Ÿ

---

### 2.3 DaemonSet èŠ‚ç‚¹çº§éƒ¨ç½²

```yaml
# experiments/02-controllers/daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: daemon-demo
  namespace: experiments
spec:
  selector:
    matchLabels:
      app: daemon-demo
  template:
    metadata:
      labels:
        app: daemon-demo
    spec:
      containers:
      - name: logger
        image: busybox
        command: ["sh", "-c", "while true; do echo \"Node: $NODE_NAME - $(date)\"; sleep 30; done"]
        env:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
```

**è§‚å¯Ÿå‘½ä»¤**:
```bash
kubectl apply -f experiments/02-controllers/daemonset.yaml

# æŸ¥çœ‹æ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„Pod
kubectl get pods -n experiments -l app=daemon-demo -o wide

# æŸ¥çœ‹èŠ‚ç‚¹æ ‡ç­¾
kubectl get nodes --show-labels

# æ·»åŠ èŠ‚ç‚¹é€‰æ‹©å™¨æµ‹è¯•ï¼ˆå¦‚æœæœ‰å¤šèŠ‚ç‚¹ï¼‰
kubectl patch daemonset daemon-demo -n experiments -p '{"spec":{"template":{"spec":{"nodeSelector":{"kubernetes.io/os":"linux"}}}}}'
```

---

# ğŸ“– å®éªŒä¸‰ï¼šç½‘ç»œåŸç†æ¢ç´¢

## ğŸ¯ å­¦ä¹ ç›®æ ‡
- ç†è§£ Service çš„å››ç§ç±»å‹å’Œè´Ÿè½½å‡è¡¡æœºåˆ¶
- æŒæ¡ Ingress çš„è·¯ç”±è§„åˆ™
- å®è·µ NetworkPolicy ç½‘ç»œéš”ç¦»

## ğŸ”¬ å®éªŒæ­¥éª¤

### 3.1 Service ç±»å‹å¯¹æ¯”å®éªŒ

```yaml
# experiments/03-networking/service-types.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
  namespace: experiments
spec:
  replicas: 3
  selector:
    matchLabels:
      app: web-app
  template:
    metadata:
      labels:
        app: web-app
    spec:
      containers:
      - name: app
        image: hashicorp/http-echo
        args:
        - "-text=Pod: $(POD_NAME) on Node: $(NODE_NAME)"
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        ports:
        - containerPort: 5678
---
# ClusterIP Service
apiVersion: v1
kind: Service
metadata:
  name: web-clusterip
  namespace: experiments
spec:
  type: ClusterIP
  selector:
    app: web-app
  ports:
  - port: 80
    targetPort: 5678
---
# NodePort Service
apiVersion: v1
kind: Service
metadata:
  name: web-nodeport
  namespace: experiments
spec:
  type: NodePort
  selector:
    app: web-app
  ports:
  - port: 80
    targetPort: 5678
    nodePort: 30080
```

**å®éªŒä»»åŠ¡**:
```bash
kubectl apply -f experiments/03-networking/service-types.yaml

# æŸ¥çœ‹Serviceå’ŒEndpoints
kubectl get svc -n experiments
kubectl get endpoints -n experiments

# æµ‹è¯•ClusterIPè®¿é—®
kubectl run -it --rm curl --image=curlimages/curl --restart=Never -n experiments -- curl http://web-clusterip

# å¤šæ¬¡è¯·æ±‚è§‚å¯Ÿè´Ÿè½½å‡è¡¡
for i in {1..10}; do
  kubectl run curl-$i --image=curlimages/curl --restart=Never -n experiments --rm -- curl -s http://web-clusterip
done

# æµ‹è¯•NodePortï¼ˆä»ä¸»æœºè®¿é—®ï¼‰
curl http://localhost:30080

# æŸ¥çœ‹iptablesè§„åˆ™ï¼ˆServiceå®ç°åŸç†ï¼‰
docker exec kind-homelab-control-plane iptables-save | grep web-clusterip
```

**å…³é”®é—®é¢˜**:
- Service å¦‚ä½•å‘ç°åç«¯ Podï¼Ÿ
- è´Ÿè½½å‡è¡¡æ˜¯å¦‚ä½•å®ç°çš„ï¼ˆkube-proxy æ¨¡å¼ï¼‰ï¼Ÿ
- ClusterIP å’Œ NodePort çš„ç½‘ç»œè·¯å¾„æœ‰ä½•ä¸åŒï¼Ÿ

---

### 3.2 Headless Service å’Œ DNS å®éªŒ

```yaml
# experiments/03-networking/headless-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: web-headless
  namespace: experiments
spec:
  clusterIP: None  # Headless
  selector:
    app: web-app
  ports:
  - port: 80
    targetPort: 5678
```

**DNS æ¢ç´¢**:
```bash
kubectl apply -f experiments/03-networking/headless-service.yaml

# æŸ¥çœ‹Serviceï¼ˆæ²¡æœ‰ClusterIPï¼‰
kubectl get svc web-headless -n experiments

# DNSè§£æå¯¹æ¯”
kubectl run -it --rm debug --image=busybox --restart=Never -n experiments -- sh

# åœ¨debug Podä¸­æ‰§è¡Œ
nslookup web-clusterip.experiments.svc.cluster.local
nslookup web-headless.experiments.svc.cluster.local

# è§‚å¯ŸHeadless Serviceè¿”å›æ‰€æœ‰Pod IP
```

---

### 3.3 NetworkPolicy ç½‘ç»œéš”ç¦»

```yaml
# experiments/03-networking/network-policy.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
  namespace: experiments
spec:
  replicas: 2
  selector:
    matchLabels:
      app: backend
      tier: backend
  template:
    metadata:
      labels:
        app: backend
        tier: backend
    spec:
      containers:
      - name: app
        image: nginx:alpine
---
apiVersion: v1
kind: Service
metadata:
  name: backend-svc
  namespace: experiments
spec:
  selector:
    app: backend
  ports:
  - port: 80
---
# åªå…è®¸æ¥è‡ªfrontendçš„æµé‡
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: backend-policy
  namespace: experiments
spec:
  podSelector:
    matchLabels:
      tier: backend
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          tier: frontend
    ports:
    - protocol: TCP
      port: 80
```

**æµ‹è¯•ç½‘ç»œéš”ç¦»**:
```bash
kubectl apply -f experiments/03-networking/network-policy.yaml

# ä»éfrontend Podè®¿é—®ï¼ˆåº”è¯¥è¢«æ‹’ç»ï¼‰
kubectl run test-access --image=busybox --restart=Never -n experiments -- wget -T 5 -O- http://backend-svc

# åˆ›å»ºfrontend Podæµ‹è¯•
kubectl run frontend --image=busybox --restart=Never -n experiments --labels="tier=frontend" -- wget -T 5 -O- http://backend-svc

# è§‚å¯Ÿç»“æœå·®å¼‚
kubectl logs test-access -n experiments
kubectl logs frontend -n experiments
```

---

# ğŸ“– å®éªŒå››ï¼šå­˜å‚¨ä¸æŒä¹…åŒ–

## ğŸ¯ å­¦ä¹ ç›®æ ‡
- ç†è§£ Volumeã€PVã€PVC çš„å…³ç³»
- æŒæ¡ StorageClass åŠ¨æ€ä¾›åº”
- å®è·µæ•°æ®æŒä¹…åŒ–å’Œè¿ç§»

## ğŸ”¬ å®éªŒæ­¥éª¤

### 4.1 Volume ç±»å‹å¯¹æ¯”

```yaml
# experiments/04-storage/volume-types.yaml
apiVersion: v1
kind: Pod
metadata:
  name: volume-demo
  namespace: experiments
spec:
  containers:
  - name: writer
    image: busybox
    command: ["sh", "-c", "while true; do date >> /data/emptyDir/log.txt; date >> /data/hostPath/log.txt; sleep 5; done"]
    volumeMounts:
    - name: empty-vol
      mountPath: /data/emptyDir
    - name: host-vol
      mountPath: /data/hostPath
  - name: reader
    image: busybox
    command: ["sh", "-c", "tail -f /data/emptyDir/log.txt"]
    volumeMounts:
    - name: empty-vol
      mountPath: /data/emptyDir
  volumes:
  - name: empty-vol
    emptyDir: {}
  - name: host-vol
    hostPath:
      path: /tmp/k8s-data
      type: DirectoryOrCreate
```

**å®éªŒä»»åŠ¡**:
```bash
kubectl apply -f experiments/04-storage/volume-types.yaml

# æŸ¥çœ‹æ—¥å¿—
kubectl logs volume-demo -n experiments -c reader

# åˆ é™¤PodåæŸ¥çœ‹æ•°æ®
kubectl delete pod volume-demo -n experiments

# é‡æ–°åˆ›å»ºï¼Œè§‚å¯ŸemptyDiræ•°æ®ä¸¢å¤±ï¼ŒhostPathæ•°æ®ä¿ç•™
kubectl apply -f experiments/04-storage/volume-types.yaml
docker exec kind-homelab-control-plane cat /tmp/k8s-data/log.txt
```

**å…³é”®é—®é¢˜**:
- emptyDir å’Œ hostPath çš„ç”Ÿå‘½å‘¨æœŸæœ‰ä½•ä¸åŒï¼Ÿ
- å¤šå®¹å™¨å¦‚ä½•å…±äº« Volumeï¼Ÿ

---

### 4.2 PV å’Œ PVC å®éªŒ

```yaml
# experiments/04-storage/pv-pvc.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-demo
spec:
  capacity:
    storage: 1Gi
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: manual
  hostPath:
    path: /tmp/pv-data
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-demo
  namespace: experiments
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 500Mi
  storageClassName: manual
---
apiVersion: v1
kind: Pod
metadata:
  name: pvc-user
  namespace: experiments
spec:
  containers:
  - name: app
    image: nginx:alpine
    volumeMounts:
    - name: storage
      mountPath: /usr/share/nginx/html
  volumes:
  - name: storage
    persistentVolumeClaim:
      claimName: pvc-demo
```

**è§‚å¯Ÿç»‘å®šè¿‡ç¨‹**:
```bash
kubectl apply -f experiments/04-storage/pv-pvc.yaml

# æŸ¥çœ‹PVå’ŒPVCçŠ¶æ€
kubectl get pv
kubectl get pvc -n experiments

# å†™å…¥æ•°æ®
kubectl exec pvc-user -n experiments -- sh -c "echo 'Persistent Data' > /usr/share/nginx/html/index.html"

# åˆ é™¤Podï¼Œé‡æ–°åˆ›å»ºï¼ŒéªŒè¯æ•°æ®æŒä¹…æ€§
kubectl delete pod pvc-user -n experiments
kubectl apply -f experiments/04-storage/pv-pvc.yaml
kubectl exec pvc-user -n experiments -- cat /usr/share/nginx/html/index.html

# æŸ¥çœ‹PVå›æ”¶ç­–ç•¥
kubectl describe pv pv-demo
```

---

### 4.3 StorageClass åŠ¨æ€ä¾›åº”

```yaml
# experiments/04-storage/storageclass.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: dynamic-pvc
  namespace: experiments
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  storageClassName: standard  # Kindé»˜è®¤çš„StorageClass
---
apiVersion: v1
kind: Pod
metadata:
  name: dynamic-user
  namespace: experiments
spec:
  containers:
  - name: app
    image: busybox
    command: ["sh", "-c", "echo 'Dynamic Storage' > /data/test.txt && sleep 3600"]
    volumeMounts:
    - name: storage
      mountPath: /data
  volumes:
  - name: storage
    persistentVolumeClaim:
      claimName: dynamic-pvc
```

**è§‚å¯ŸåŠ¨æ€ä¾›åº”**:
```bash
kubectl apply -f experiments/04-storage/storageclass.yaml

# æŸ¥çœ‹è‡ªåŠ¨åˆ›å»ºçš„PV
kubectl get pv
kubectl get pvc dynamic-pvc -n experiments

# æŸ¥çœ‹StorageClass
kubectl get storageclass
kubectl describe storageclass standard
```

---

# ğŸ“– å®éªŒäº”ï¼šé…ç½®ç®¡ç†

## ğŸ¯ å­¦ä¹ ç›®æ ‡
- æŒæ¡ ConfigMap å’Œ Secret çš„ä½¿ç”¨
- ç†è§£é…ç½®çƒ­æ›´æ–°æœºåˆ¶
- å®è·µæ•æ„Ÿä¿¡æ¯ä¿æŠ¤

## ğŸ”¬ å®éªŒæ­¥éª¤

### 5.1 ConfigMap å¤šç§æŒ‚è½½æ–¹å¼

```yaml
# experiments/05-config/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: experiments
data:
  app.properties: |
    server.port=8080
    server.name=demo
    debug.enabled=true
  log.level: "INFO"
  feature.flags: "feature1,feature2,feature3"
---
apiVersion: v1
kind: Pod
metadata:
  name: config-demo
  namespace: experiments
spec:
  containers:
  - name: app
    image: busybox
    command: ["sh", "-c", "while true; do echo 'LOG_LEVEL: '$LOG_LEVEL; cat /config/app.properties; sleep 30; done"]
    env:
    # æ–¹å¼1: ç¯å¢ƒå˜é‡
    - name: LOG_LEVEL
      valueFrom:
        configMapKeyRef:
          name: app-config
          key: log.level
    # æ–¹å¼2: å…¨éƒ¨å¯¼å…¥ä¸ºç¯å¢ƒå˜é‡
    envFrom:
    - configMapRef:
        name: app-config
        prefix: CONFIG_
    volumeMounts:
    # æ–¹å¼3: æ–‡ä»¶æŒ‚è½½
    - name: config-volume
      mountPath: /config
  volumes:
  - name: config-volume
    configMap:
      name: app-config
```

**å®éªŒä»»åŠ¡**:
```bash
kubectl apply -f experiments/05-config/configmap.yaml

# æŸ¥çœ‹é…ç½®ä½¿ç”¨
kubectl logs config-demo -n experiments

# è¿›å…¥å®¹å™¨éªŒè¯
kubectl exec config-demo -n experiments -- env | grep CONFIG
kubectl exec config-demo -n experiments -- ls /config
kubectl exec config-demo -n experiments -- cat /config/app.properties

# ä¿®æ”¹ConfigMapè§‚å¯Ÿå˜åŒ–
kubectl edit configmap app-config -n experiments
# ä¿®æ”¹ log.level ä¸º DEBUG

# ç¯å¢ƒå˜é‡ä¸ä¼šæ›´æ–°ï¼Œæ–‡ä»¶ä¼šæ›´æ–°ï¼ˆéœ€è¦ç­‰å¾…çº¦1åˆ†é’Ÿï¼‰
kubectl exec config-demo -n experiments -- cat /config/app.properties
```

**å…³é”®é—®é¢˜**:
- ConfigMap æ›´æ–°åï¼Œå“ªäº›æ–¹å¼ä¼šè‡ªåŠ¨æ›´æ–°ï¼Ÿ
- å¦‚ä½•å®ç°åº”ç”¨çš„é…ç½®çƒ­æ›´æ–°ï¼Ÿ

---

### 5.2 Secret æ•æ„Ÿä¿¡æ¯ç®¡ç†

```yaml
# experiments/05-config/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: db-secret
  namespace: experiments
type: Opaque
stringData:
  username: admin
  password: super-secret-password
  database-url: "postgresql://db.example.com:5432/mydb"
---
apiVersion: v1
kind: Pod
metadata:
  name: secret-demo
  namespace: experiments
spec:
  containers:
  - name: app
    image: busybox
    command: ["sh", "-c", "echo 'DB_USER: '$DB_USER; echo 'DB_PASS: [HIDDEN]'; cat /secrets/database-url; sleep 3600"]
    env:
    - name: DB_USER
      valueFrom:
        secretKeyRef:
          name: db-secret
          key: username
    - name: DB_PASS
      valueFrom:
        secretKeyRef:
          name: db-secret
          key: password
    volumeMounts:
    - name: secret-volume
      mountPath: /secrets
      readOnly: true
  volumes:
  - name: secret-volume
    secret:
      secretName: db-secret
      items:
      - key: database-url
        path: database-url
```

**å®éªŒä»»åŠ¡**:
```bash
kubectl apply -f experiments/05-config/secret.yaml

# æŸ¥çœ‹Secretï¼ˆå·²ç¼–ç ï¼‰
kubectl get secret db-secret -n experiments -o yaml

# è§£ç Secret
kubectl get secret db-secret -n experiments -o jsonpath='{.data.password}' | base64 -d

# éªŒè¯Podä½¿ç”¨
kubectl logs secret-demo -n experiments
kubectl exec secret-demo -n experiments -- cat /secrets/database-url
```

---

# ğŸ“– å®éªŒå…­ï¼šRBAC å’Œå®‰å…¨

## ğŸ¯ å­¦ä¹ ç›®æ ‡
- ç†è§£ K8s çš„è®¤è¯å’Œæˆæƒæœºåˆ¶
- æŒæ¡ RBAC çš„é…ç½®
- å®è·µæœ€å°æƒé™åŸåˆ™

## ğŸ”¬ å®éªŒæ­¥éª¤

### 6.1 ServiceAccount å’Œ RBAC å®éªŒ

```yaml
# experiments/06-security/rbac-demo.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: pod-reader
  namespace: experiments
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: pod-reader-role
  namespace: experiments
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: pod-reader-binding
  namespace: experiments
subjects:
- kind: ServiceAccount
  name: pod-reader
  namespace: experiments
roleRef:
  kind: Role
  name: pod-reader-role
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: v1
kind: Pod
metadata:
  name: rbac-test
  namespace: experiments
spec:
  serviceAccountName: pod-reader
  containers:
  - name: kubectl
    image: bitnami/kubectl:latest
    command: ["sleep", "3600"]
```

**æƒé™æµ‹è¯•**:
```bash
kubectl apply -f experiments/06-security/rbac-demo.yaml

# è¿›å…¥Podæµ‹è¯•æƒé™
kubectl exec -it rbac-test -n experiments -- bash

# åœ¨Podå†…æ‰§è¡Œï¼š
# å¯ä»¥æ‰§è¡Œï¼ˆæœ‰æƒé™ï¼‰
kubectl get pods -n experiments

# æ— æ³•æ‰§è¡Œï¼ˆæ— æƒé™ï¼‰
kubectl get deployments -n experiments
kubectl delete pod lifecycle-demo -n experiments
kubectl get pods -n default

# é€€å‡ºPod
exit

# æŸ¥çœ‹ServiceAccount token
kubectl exec rbac-test -n experiments -- cat /var/run/secrets/kubernetes.io/serviceaccount/token
```

**æƒé™æ‰©å±•å®éªŒ**:
```bash
# æ·»åŠ åˆ é™¤æƒé™
kubectl apply -f - <<EOF
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: pod-manager-role
  namespace: experiments
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch", "delete"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: pod-manager-binding
  namespace: experiments
subjects:
- kind: ServiceAccount
  name: pod-reader
  namespace: experiments
roleRef:
  kind: Role
  name: pod-manager-role
  apiGroup: rbac.authorization.k8s.io
EOF

# é‡æ–°æµ‹è¯•åˆ é™¤æƒé™
kubectl exec -it rbac-test -n experiments -- kubectl delete pod config-demo -n experiments
```

**å…³é”®é—®é¢˜**:
- ServiceAccountã€Roleã€RoleBinding çš„å…³ç³»ï¼Ÿ
- Role å’Œ ClusterRole çš„åŒºåˆ«ï¼Ÿ
- å¦‚ä½•è°ƒè¯•æƒé™é—®é¢˜ï¼Ÿ

---

### 6.2 SecurityContext å®éªŒ

```yaml
# experiments/06-security/security-context.yaml
apiVersion: v1
kind: Pod
metadata:
  name: security-demo
  namespace: experiments
spec:
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
  containers:
  - name: app
    image: busybox
    command: ["sh", "-c", "id; ls -l /data; echo 'test' > /data/test.txt; ls -l /data; sleep 3600"]
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      readOnlyRootFilesystem: false
    volumeMounts:
    - name: data
      mountPath: /data
  volumes:
  - name: data
    emptyDir: {}
```

**å®‰å…¨å®éªŒ**:
```bash
kubectl apply -f experiments/06-security/security-context.yaml

# æŸ¥çœ‹è¿è¡Œç”¨æˆ·å’Œæƒé™
kubectl logs security-demo -n experiments

# å°è¯•ææƒæ“ä½œï¼ˆåº”è¯¥å¤±è´¥ï¼‰
kubectl exec security-demo -n experiments -- sh -c "id && whoami"
```

---

# ğŸ“– å®éªŒä¸ƒï¼šè°ƒåº¦æœºåˆ¶æ¢ç´¢

## ğŸ¯ å­¦ä¹ ç›®æ ‡
- ç†è§£ Kubernetes è°ƒåº¦å™¨å·¥ä½œåŸç†
- æŒæ¡èŠ‚ç‚¹äº²å’Œæ€§å’Œ Pod äº²å’Œæ€§
- å®è·µ Taints å’Œ Tolerations

## ğŸ”¬ å®éªŒæ­¥éª¤

### 7.1 èµ„æºè¯·æ±‚å’Œé™åˆ¶

```yaml
# experiments/07-scheduling/resources.yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-demo
  namespace: experiments
spec:
  containers:
  - name: app
    image: nginx:alpine
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"
        cpu: "500m"
```

**è§‚å¯Ÿè°ƒåº¦**:
```bash
kubectl apply -f experiments/07-scheduling/resources.yaml

# æŸ¥çœ‹Podèµ„æºä½¿ç”¨
kubectl top pod resource-demo -n experiments

# æŸ¥çœ‹èŠ‚ç‚¹å¯ç”¨èµ„æº
kubectl top nodes

# åˆ›å»ºèµ„æºè¿‡å¤§çš„Podè§‚å¯Ÿè°ƒåº¦å¤±è´¥
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: huge-resource
  namespace: experiments
spec:
  containers:
  - name: app
    image: nginx:alpine
    resources:
      requests:
        memory: "1000Gi"
        cpu: "1000"
EOF

# æŸ¥çœ‹è°ƒåº¦å¤±è´¥äº‹ä»¶
kubectl describe pod huge-resource -n experiments
```

---

### 7.2 èŠ‚ç‚¹äº²å’Œæ€§å®éªŒ

```yaml
# experiments/07-scheduling/node-affinity.yaml
apiVersion: v1
kind: Pod
metadata:
  name: affinity-demo
  namespace: experiments
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: kubernetes.io/os
            operator: In
            values:
            - linux
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 1
        preference:
          matchExpressions:
          - key: node-role.kubernetes.io/control-plane
            operator: Exists
  containers:
  - name: app
    image: nginx:alpine
```

**è°ƒåº¦æµ‹è¯•**:
```bash
# æŸ¥çœ‹èŠ‚ç‚¹æ ‡ç­¾
kubectl get nodes --show-labels

# åº”ç”¨Pod
kubectl apply -f experiments/07-scheduling/node-affinity.yaml

# æŸ¥çœ‹Podè°ƒåº¦åˆ°å“ªä¸ªèŠ‚ç‚¹
kubectl get pod affinity-demo -n experiments -o wide

# ä¸ºèŠ‚ç‚¹æ·»åŠ è‡ªå®šä¹‰æ ‡ç­¾
kubectl label nodes kind-homelab-control-plane env=production

# ä¿®æ”¹nodeAffinityä½¿ç”¨è‡ªå®šä¹‰æ ‡ç­¾
```

---

### 7.3 Pod äº²å’Œæ€§å’Œåäº²å’Œæ€§

```yaml
# experiments/07-scheduling/pod-affinity.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-tier
  namespace: experiments
spec:
  replicas: 2
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
        tier: frontend
    spec:
      containers:
      - name: web
        image: nginx:alpine
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cache-tier
  namespace: experiments
spec:
  replicas: 2
  selector:
    matchLabels:
      app: cache
  template:
    metadata:
      labels:
        app: cache
        tier: backend
    spec:
      affinity:
        # å€¾å‘äºå’Œweb-tieråœ¨åŒä¸€èŠ‚ç‚¹
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: tier
                  operator: In
                  values:
                  - frontend
              topologyKey: kubernetes.io/hostname
        # é¿å…å¤šä¸ªcache Podåœ¨åŒä¸€èŠ‚ç‚¹
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - cache
              topologyKey: kubernetes.io/hostname
      containers:
      - name: cache
        image: redis:alpine
```

**è§‚å¯Ÿè°ƒåº¦ç­–ç•¥**:
```bash
kubectl apply -f experiments/07-scheduling/pod-affinity.yaml

# æŸ¥çœ‹Podåˆ†å¸ƒ
kubectl get pods -n experiments -o wide -l app=web
kubectl get pods -n experiments -o wide -l app=cache

# åˆ†æè°ƒåº¦ç»“æœ
```

---

# ğŸ“– å®éªŒå…«ï¼šç›‘æ§å’Œå¯è§‚æµ‹æ€§

## ğŸ¯ å­¦ä¹ ç›®æ ‡
- åˆ©ç”¨ Prometheus æ”¶é›†æŒ‡æ ‡
- ä½¿ç”¨ Grafana å¯è§†åŒ–
- å®è·µæ—¥å¿—èšåˆå’Œè¿½è¸ª

## ğŸ”¬ å®éªŒæ­¥éª¤

### 8.1 åº”ç”¨æŒ‡æ ‡æš´éœ²

```yaml
# experiments/08-monitoring/metrics-app.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: metrics-demo
  namespace: experiments
spec:
  replicas: 2
  selector:
    matchLabels:
      app: metrics-demo
  template:
    metadata:
      labels:
        app: metrics-demo
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      containers:
      - name: app
        image: nginx:alpine
        ports:
        - containerPort: 80
        - containerPort: 8080
          name: metrics
---
apiVersion: v1
kind: Service
metadata:
  name: metrics-demo
  namespace: experiments
  labels:
    app: metrics-demo
spec:
  selector:
    app: metrics-demo
  ports:
  - name: http
    port: 80
    targetPort: 80
  - name: metrics
    port: 8080
    targetPort: 8080
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: metrics-demo
  namespace: experiments
spec:
  selector:
    matchLabels:
      app: metrics-demo
  endpoints:
  - port: metrics
    interval: 30s
```

**ç›‘æ§å®éªŒ**:
```bash
kubectl apply -f experiments/08-monitoring/metrics-app.yaml

# ç«¯å£è½¬å‘è®¿é—®Prometheus
kubectl port-forward -n monitoring svc/prometheus-operated 9090:9090 &

# åœ¨æµè§ˆå™¨è®¿é—® http://localhost:9090
# æŸ¥è¯¢: up{job="experiments/metrics-demo"}

# ç«¯å£è½¬å‘è®¿é—®Grafana
kubectl port-forward -n monitoring svc/grafana 3000:80 &

# è®¿é—® http://localhost:3000 (admin/admin123)
# åˆ›å»ºDashboardå±•ç¤ºåº”ç”¨æŒ‡æ ‡
```

---

### 8.2 è‡ªå®šä¹‰æŒ‡æ ‡å®éªŒ

åˆ›å»ºä¸€ä¸ªå¸¦æœ‰è‡ªå®šä¹‰æŒ‡æ ‡çš„åº”ç”¨ï¼š

```yaml
# experiments/08-monitoring/custom-metrics-app.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: custom-app-script
  namespace: experiments
data:
  app.sh: |
    #!/bin/sh
    # ç®€å•çš„Prometheusæ ¼å¼æŒ‡æ ‡æœåŠ¡å™¨
    while true; do
      echo -e "HTTP/1.1 200 OK\r\nContent-Type: text/plain\r\n\r\n# HELP custom_requests_total Total requests\n# TYPE custom_requests_total counter\ncustom_requests_total $RANDOM\n# HELP custom_active_users Active users\n# TYPE custom_active_users gauge\ncustom_active_users $((RANDOM % 100))\n" | nc -l -p 8080
    done
---
apiVersion: v1
kind: Pod
metadata:
  name: custom-metrics
  namespace: experiments
  labels:
    app: custom-metrics
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8080"
spec:
  containers:
  - name: app
    image: busybox
    command: ["sh", "/scripts/app.sh"]
    ports:
    - containerPort: 8080
      name: metrics
    volumeMounts:
    - name: script
      mountPath: /scripts
  volumes:
  - name: config configMap:
      name: custom-app-script
      defaultMode: 0755
```

**æŸ¥è¯¢è‡ªå®šä¹‰æŒ‡æ ‡**:
```bash
kubectl apply -f experiments/08-monitoring/custom-metrics-app.yaml

# æœ¬åœ°æµ‹è¯•æŒ‡æ ‡ç«¯ç‚¹
kubectl port-forward custom-metrics 8080:8080 -n experiments &
curl http://localhost:8080

# åœ¨Prometheusä¸­æŸ¥è¯¢
# custom_requests_total
# custom_active_users
```

---

### 8.3 æ—¥å¿—èšåˆå®éªŒ

```yaml
# experiments/08-monitoring/logging-app.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: logging-demo
  namespace: experiments
spec:
  replicas: 2
  selector:
    matchLabels:
      app: logging-demo
  template:
    metadata:
      labels:
        app: logging-demo
    spec:
      containers:
      - name: app
        image: busybox
        command:
        - sh
        - -c
        - |
          while true; do
            echo "{\"timestamp\":\"$(date -Iseconds)\", \"level\":\"INFO\", \"message\":\"Request processed\", \"user\":\"user-$RANDOM\", \"duration_ms\":$((RANDOM % 1000))}"
            sleep 2
            if [ $((RANDOM % 10)) -eq 0 ]; then
              echo "{\"timestamp\":\"$(date -Iseconds)\", \"level\":\"ERROR\", \"message\":\"Failed to process request\", \"error\":\"Connection timeout\"}"
            fi
          done
```

**æ—¥å¿—å®éªŒ**:
```bash
kubectl apply -f experiments/08-monitoring/logging-app.yaml

# æŸ¥çœ‹æ—¥å¿—
kubectl logs -f -n experiments -l app=logging-demo

# å¤šPodæ—¥å¿—èšåˆ
kubectl logs -n experiments -l app=logging-demo --tail=20 --prefix

# ä½¿ç”¨sternå·¥å…·ï¼ˆå¦‚æœå®‰è£…ï¼‰
# stern -n experiments logging-demo

# åœ¨Grafanaä¸­æŸ¥çœ‹Lokiæ—¥å¿—
# æŸ¥è¯¢: {namespace="experiments", app="logging-demo"}
# è¿‡æ»¤é”™è¯¯: {namespace="experiments", app="logging-demo"} |= "ERROR"
```

---

# ğŸ“– å®éªŒä¹ï¼šGitOps æ·±å…¥å®è·µ

## ğŸ¯ å­¦ä¹ ç›®æ ‡
- ç†è§£ Flux çš„ GitOps å·¥ä½œæµ
- æŒæ¡ Kustomization å’Œ HelmRelease
- å®è·µå£°æ˜å¼é…ç½®ç®¡ç†

## ğŸ”¬ å®éªŒæ­¥éª¤

### 9.1 Flux GitRepository å®éªŒ

```yaml
# experiments/09-gitops/git-source.yaml
apiVersion: source.toolkit.fluxcd.io/v1
kind: GitRepository
metadata:
  name: experiment-repo
  namespace: experiments
spec:
  interval: 1m
  url: https://github.com/waynelw/homelab
  ref:
    branch: main
  ignore: |
    # exclude all
    /*
    # include experiments directory
    !/experiments/09-gitops/manifests
```

**è§‚å¯Ÿ Flux åŒæ­¥**:
```bash
# åˆ›å»ºnamespaceå¹¶åº”ç”¨
kubectl create namespace experiments --dry-run=client -o yaml | kubectl apply -f -
kubectl apply -f experiments/09-gitops/git-source.yaml

# æŸ¥çœ‹GitRepositoryçŠ¶æ€
kubectl get gitrepository -n experiments
kubectl describe gitrepository experiment-repo -n experiments

# æŸ¥çœ‹Fluxæ—¥å¿—
flux logs --level=debug -n experiments
```

---

### 9.2 Kustomization å£°æ˜å¼éƒ¨ç½²

åˆ›å»ºä¸€ä¸ªé€šè¿‡ Flux ç®¡ç†çš„åº”ç”¨ï¼š

```yaml
# experiments/09-gitops/kustomization.yaml
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: experiment-app
  namespace: experiments
spec:
  interval: 5m
  path: ./experiments/09-gitops/manifests
  prune: true
  sourceRef:
    kind: GitRepository
    name: experiment-repo
  healthChecks:
  - apiVersion: apps/v1
    kind: Deployment
    name: gitops-demo
    namespace: experiments
```

å¯¹åº”çš„åº”ç”¨é…ç½®ï¼š
```yaml
# experiments/09-gitops/manifests/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gitops-demo
  namespace: experiments
spec:
  replicas: 2
  selector:
    matchLabels:
      app: gitops-demo
  template:
    metadata:
      labels:
        app: gitops-demo
    spec:
      containers:
      - name: app
        image: nginx:1.21-alpine
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: gitops-demo
  namespace: experiments
spec:
  selector:
    app: gitops-demo
  ports:
  - port: 80
```

**GitOps å·¥ä½œæµ**:
```bash
# åº”ç”¨Kustomization
kubectl apply -f experiments/09-gitops/kustomization.yaml

# è§‚å¯ŸFluxè‡ªåŠ¨éƒ¨ç½²
kubectl get kustomization -n experiments -w
flux get kustomizations -n experiments

# ä¿®æ”¹Gitä»“åº“ä¸­çš„é…ç½®ï¼ˆä¾‹å¦‚ä¿®æ”¹replicasï¼‰
# è§‚å¯ŸFluxè‡ªåŠ¨åŒæ­¥
flux reconcile kustomization experiment-app -n experiments

# æŸ¥çœ‹éƒ¨ç½²çŠ¶æ€
kubectl get deployment gitops-demo -n experiments
```

---

### 9.3 HelmRelease ç®¡ç†

```yaml
# experiments/09-gitops/helm-release.yaml
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: bitnami
  namespace: experiments
spec:
  interval: 1h
  url: https://charts.bitnami.com/bitnami
---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: redis
  namespace: experiments
spec:
  interval: 5m
  chart:
    spec:
      chart: redis
      version: "17.x"
      sourceRef:
        kind: HelmRepository
        name: bitnami
  values:
    architecture: standalone
    auth:
      enabled: false
    master:
      resources:
        requests:
          cpu: 100m
          memory: 128Mi
        limits:
          cpu: 200m
          memory: 256Mi
```

**Helm ç®¡ç†å®éªŒ**:
```bash
kubectl apply -f experiments/09-gitops/helm-release.yaml

# è§‚å¯ŸHelmå®‰è£…è¿‡ç¨‹
kubectl get helmrelease -n experiments -w
flux get helmreleases -n experiments

# æŸ¥çœ‹å®‰è£…çš„èµ„æº
kubectl get pods -n experiments -l app.kubernetes.io/name=redis

# ä¿®æ”¹valuesï¼ˆä¾‹å¦‚å¢åŠ resourcesï¼‰
kubectl edit helmrelease redis -n experiments

# è§‚å¯Ÿæ»šåŠ¨æ›´æ–°
kubectl rollout status statefulset redis-master -n experiments
```

---

# ğŸ“– å®éªŒåï¼šTekton CI/CD æ·±å…¥

## ğŸ¯ å­¦ä¹ ç›®æ ‡
- ç†è§£ Tekton Task å’Œ Pipeline è®¾è®¡
- æŒæ¡ Workspace å’Œå‚æ•°ä¼ é€’
- å®è·µå®Œæ•´çš„ CI/CD æµç¨‹

## ğŸ”¬ å®éªŒæ­¥éª¤

### 10.1 åˆ›å»ºå¤æ‚çš„ Task

```yaml
# experiments/10-tekton/test-task.yaml
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  name: run-tests
  namespace: experiments
spec:
  params:
  - name: test-type
    type: string
    default: "unit"
  workspaces:
  - name: source
  results:
  - name: test-result
    description: Test execution result
  steps:
  - name: run-unit-tests
    image: python:3.9-slim
    workingDir: $(workspaces.source.path)
    script: |
      #!/usr/bin/env bash
      set -e
      echo "Running $(params.test-type) tests..."
      
      # æ¨¡æ‹Ÿæµ‹è¯•
      if [ "$(params.test-type)" == "unit" ]; then
        echo "âœ“ test_user_login: passed"
        echo "âœ“ test_data_validation: passed"
        echo "âœ“ test_api_endpoints: passed"
        echo "PASS" | tee $(results.test-result.path)
      elif [ "$(params.test-type)" == "integration" ]; then
        echo "âœ“ test_database_connection: passed"
        echo "âœ“ test_api_integration: passed"
        echo "PASS" | tee $(results.test-result.path)
      else
        echo "Unknown test type"
        echo "FAIL" | tee $(results.test-result.path)
        exit 1
      fi
  - name: generate-report
    image: busybox
    script: |
      #!/bin/sh
      echo "=== Test Report ==="
      echo "Test Type: $(params.test-type)"
      echo "Result: $(cat $(results.test-result.path))"
      echo "Timestamp: $(date)"
```

---

### 10.2 æ„å»ºå®Œæ•´çš„ CI Pipeline

```yaml
# experiments/10-tekton/ci-pipeline.yaml
apiVersion: tekton.dev/v1beta1
kind: Pipeline
metadata:
  name: full-ci-pipeline
  namespace: experiments
spec:
  params:
  - name: git-url
    type: string
  - name: git-revision
    type: string
    default: main
  - name: image-name
    type: string
  workspaces:
  - name: shared-workspace
  tasks:
  # Task 1: Cloneæºç 
  - name: fetch-repository
    taskRef:
      name: git-clone-simple
    workspaces:
    - name: output
      workspace: shared-workspace
    params:
    - name: url
      value: $(params.git-url)
    - name: revision
      value: $(params.git-revision)
  
  # Task 2: è¿è¡Œå•å…ƒæµ‹è¯•
  - name: unit-tests
    taskRef:
      name: run-tests
    runAfter:
    - fetch-repository
    workspaces:
    - name: source
      workspace: shared-workspace
    params:
    - name: test-type
      value: "unit"
  
  # Task 3: ä»£ç è´¨é‡æ£€æŸ¥
  - name: code-quality
    runAfter:
    - fetch-repository
    taskSpec:
      workspaces:
      - name: source
      steps:
      - name: lint
        image: python:3.9-slim
        workingDir: $(workspaces.source.path)
        script: |
          #!/bin/bash
          echo "Running code quality checks..."
          echo "âœ“ Code style: passed"
          echo "âœ“ Security scan: passed"
          echo "âœ“ Complexity check: passed"
    workspaces:
    - name: source
      workspace: shared-workspace
  
  # Task 4: æ„å»ºé•œåƒï¼ˆå¹¶è¡Œï¼‰
  - name: build-image
    runAfter:
    - unit-tests
    - code-quality
    taskRef:
      name: build-simple
    workspaces:
    - name: source
      workspace: shared-workspace
    params:
    - name: image
      value: $(params.image-name)
  
  # Task 5: é›†æˆæµ‹è¯•
  - name: integration-tests
    taskRef:
      name: run-tests
    runAfter:
    - build-image
    workspaces:
    - name: source
      workspace: shared-workspace
    params:
    - name: test-type
      value: "integration"
  
  # Task 6: éƒ¨ç½²åˆ°ç¯å¢ƒ
  - name: deploy
    taskRef:
      name: deploy-simple
    runAfter:
    - integration-tests
    params:
    - name: image
      value: $(params.image-name)
  
  # Task 7: å¥åº·æ£€æŸ¥
  - name: health-check
    runAfter:
    - deploy
    taskSpec:
      steps:
      - name: check
        image: curlimages/curl
        script: |
          #!/bin/sh
          echo "Performing health check..."
          sleep 5
          echo "âœ“ Application is healthy"
```

**è¿è¡Œå®Œæ•´ Pipeline**:
```bash
# ç¡®ä¿ä¹‹å‰çš„Taskså·²åˆ›å»º
kubectl apply -f experiments/10-tekton/test-task.yaml
kubectl apply -f experiments/10-tekton/ci-pipeline.yaml

# åˆ›å»ºPipelineRun
kubectl create -f - <<EOF
apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  name: full-ci-run-$(date +%Y%m%d-%H%M%S)
  namespace: experiments
spec:
  pipelineRef:
    name: full-ci-pipeline
  params:
  - name: git-url
    value: "https://github.com/waynelw/homelab.git"
  - name: git-revision
    value: "main"
  - name: image-name
    value: "localhost:5000/demo-app:latest"
  workspaces:
  - name: shared-workspace
    volumeClaimTemplate:
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 1Gi
  timeout: "1h"
EOF

# è§‚å¯ŸPipelineæ‰§è¡Œ
kubectl get pipelinerun -n experiments -w

# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
tkn pipelinerun logs -f -n experiments

# æŸ¥çœ‹ä»»åŠ¡æ‹“æ‰‘ï¼ˆå¦‚æœå®‰è£…äº†Tekton Dashboardï¼‰
kubectl port-forward -n tekton-pipelines svc/tekton-dashboard 9097:9097
# è®¿é—® http://localhost:9097
```

---

### 10.3 æ¡ä»¶æ‰§è¡Œå’Œé”™è¯¯å¤„ç†

```yaml
# experiments/10-tekton/conditional-pipeline.yaml
apiVersion: tekton.dev/v1beta1
kind: Pipeline
metadata:
  name: conditional-pipeline
  namespace: experiments
spec:
  params:
  - name: deploy-env
    type: string
    default: "dev"
  - name: run-security-scan
    type: string
    default: "true"
  workspaces:
  - name: workspace
  tasks:
  - name: build
    taskSpec:
      steps:
      - name: build
        image: busybox
        script: echo "Building..."
    workspaces:
    - name: source
      workspace: workspace
  
  - name: security-scan
    when:
    - input: "$(params.run-security-scan)"
      operator: in
      values: ["true"]
    runAfter:
    - build
    taskSpec:
      steps:
      - name: scan
        image: busybox
        script: |
          echo "Running security scan..."
          echo "âœ“ No vulnerabilities found"
  
  - name: deploy-dev
    when:
    - input: "$(params.deploy-env)"
      operator: in
      values: ["dev"]
    runAfter:
    - security-scan
    taskSpec:
      steps:
      - name: deploy
        image: busybox
        script: echo "Deploying to DEV environment..."
  
  - name: deploy-prod
    when:
    - input: "$(params.deploy-env)"
      operator: in
      values: ["prod"]
    runAfter:
    - security-scan
    taskSpec:
      steps:
      - name: deploy
        image: busybox
        script: echo "Deploying to PROD environment..."
```

---

# ğŸ“Š å®éªŒå®Œæˆæ£€æŸ¥æ¸…å•

## âœ… åŸºç¡€çŸ¥è¯†æŒæ¡

- [ ] ç†è§£ Pod ç”Ÿå‘½å‘¨æœŸå’ŒçŠ¶æ€è½¬æ¢
- [ ] æŒæ¡å„ç§æ§åˆ¶å™¨çš„ä½¿ç”¨åœºæ™¯
- [ ] ç†è§£ Service çš„ç±»å‹å’Œç½‘ç»œæœºåˆ¶
- [ ] æŒæ¡å­˜å‚¨çš„æŒä¹…åŒ–æ–¹å¼
- [ ] ç†è§£é…ç½®ç®¡ç†æœ€ä½³å®è·µ

## âœ… é«˜çº§ç‰¹æ€§ç†è§£

- [ ] æŒæ¡ RBAC æƒé™é…ç½®
- [ ] ç†è§£è°ƒåº¦å™¨å·¥ä½œåŸç†
- [ ] æŒæ¡ç›‘æ§å’Œæ—¥å¿—èšåˆ
- [ ] ç†è§£ GitOps å·¥ä½œæµ
- [ ] æŒæ¡ CI/CD Pipeline è®¾è®¡

## âœ… å®è·µèƒ½åŠ›

- [ ] èƒ½å¤Ÿç‹¬ç«‹è®¾è®¡å’Œéƒ¨ç½²åº”ç”¨
- [ ] èƒ½å¤Ÿæ’æŸ¥å¸¸è§é—®é¢˜
- [ ] èƒ½å¤Ÿä¼˜åŒ–èµ„æºä½¿ç”¨
- [ ] èƒ½å¤Ÿè®¾è®¡å®‰å…¨ç­–ç•¥
- [ ] èƒ½å¤Ÿæ„å»ºå®Œæ•´çš„ CI/CD æµç¨‹

---

# ğŸ“ è¿›é˜¶å­¦ä¹ è·¯å¾„

## 1. æ·±å…¥æºç 
- é˜…è¯» Kubernetes æ ¸å¿ƒç»„ä»¶æºç 
- ç†è§£ Controller è®¾è®¡æ¨¡å¼
- ç ”ç©¶ Scheduler ç®—æ³•å®ç°

## 2. æ€§èƒ½ä¼˜åŒ–
- é›†ç¾¤æ€§èƒ½è°ƒä¼˜
- åº”ç”¨æ€§èƒ½ä¼˜åŒ–
- èµ„æºé…é¢ç®¡ç†

## 3. é«˜å¯ç”¨æ¶æ„
- å¤šé›†ç¾¤ç®¡ç†
- ç¾éš¾æ¢å¤
- è·¨åŒºåŸŸéƒ¨ç½²

## 4. æ‰©å±•å¼€å‘
- å¼€å‘ Operator
- è‡ªå®šä¹‰ CRD
- Webhook å¼€å‘

## 5. äº‘åŸç”Ÿç”Ÿæ€
- Service Mesh (Istio/Linkerd)
- Serverless (Knative)
- Edge Computing (K3s)

---

# ğŸ“ å®éªŒè®°å½•æ¨¡æ¿

ä¸ºæ¯ä¸ªå®éªŒåˆ›å»ºè®°å½•ï¼š

```markdown
## å®éªŒ X.Y: [å®éªŒåç§°]

**æ—¥æœŸ**: YYYY-MM-DD
**è€—æ—¶**: X å°æ—¶

### å®éªŒç›®æ ‡
- [ ] ç›®æ ‡ 1
- [ ] ç›®æ ‡ 2

### å®éªŒæ­¥éª¤
1. æ­¥éª¤ 1
2. æ­¥éª¤ 2

### è§‚å¯Ÿç»“æœ
- ç»“æœ 1
- ç»“æœ 2

### é‡åˆ°çš„é—®é¢˜
- é—®é¢˜ 1: æè¿° + è§£å†³æ–¹æ¡ˆ
- é—®é¢˜ 2: æè¿° + è§£å†³æ–¹æ¡ˆ

### å…³é”®æ”¶è·
- æ”¶è· 1
- æ”¶è· 2

### ä¸‹ä¸€æ­¥è®¡åˆ’
- [ ] ä»»åŠ¡ 1
- [ ] ä»»åŠ¡ 2
```

---

# ğŸ› ï¸ å®ç”¨å·¥å…·æ¨è

## è°ƒè¯•å·¥å…·
```bash
# kubectl æ’ä»¶
kubectl krew install neat      # æ¸…ç†YAMLè¾“å‡º
kubectl krew install tree      # èµ„æºæ ‘å½¢æŸ¥çœ‹
kubectl krew install tail      # æ—¥å¿—èšåˆ

# å…¶ä»–å·¥å…·
k9s                           # TUIç®¡ç†å·¥å…·
stern                         # å¤šPodæ—¥å¿—
kubectx/kubens               # ä¸Šä¸‹æ–‡åˆ‡æ¢
```

## å­¦ä¹ èµ„æº
- [Kubernetes å®˜æ–¹æ–‡æ¡£](https://kubernetes.io/docs/)
- [Kubernetes The Hard Way](https://github.com/kelseyhightower/kubernetes-the-hard-way)
- [CNCF Landscape](https://landscape.cncf.io/)

---

**ç¥ä½ å­¦ä¹ é¡ºåˆ©ï¼é€šè¿‡è¿™äº›å®éªŒï¼Œä½ å°†æ·±å…¥ç†è§£ Kubernetes çš„æ ¸å¿ƒåŸç†å’Œæœ€ä½³å®è·µã€‚** ğŸš€
